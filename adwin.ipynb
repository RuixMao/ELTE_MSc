{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: influxdb-client in c:\\users\\irenm\\anaconda3\\lib\\site-packages (1.39.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\irenm\\anaconda3\\lib\\site-packages (from influxdb-client) (2.8.2)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\users\\irenm\\anaconda3\\lib\\site-packages (from influxdb-client) (2023.11.17)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in c:\\users\\irenm\\anaconda3\\lib\\site-packages (from influxdb-client) (68.2.2)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\irenm\\anaconda3\\lib\\site-packages (from influxdb-client) (1.26.18)\n",
      "Requirement already satisfied: reactivex>=4.0.4 in c:\\users\\irenm\\anaconda3\\lib\\site-packages (from influxdb-client) (4.0.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\irenm\\anaconda3\\lib\\site-packages (from python-dateutil>=2.5.3->influxdb-client) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.1.1 in c:\\users\\irenm\\anaconda3\\lib\\site-packages (from reactivex>=4.0.4->influxdb-client) (4.7.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install influxdb-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kafka import KafkaConsumer\n",
    "from json import loads\n",
    "import json\n",
    "from time import sleep\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "import influxdb_client\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = \"FroEVNbslUfLwbOznZtPjG7mryBVgdiT_O8dIl3mJSHEGRXuZfPSw5jHfL5g2kfxRZlGKhsgJSIWfC_fpH_bbg==\"\n",
    "org = \"mema_org\"\n",
    "bucket = \"mema_bucket\"\n",
    "url = \"http://localhost:8086\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definitions of functions\n",
    "def calculate_delay_of_detection(true_change_indexes, detected_indexes):\n",
    "    \n",
    "    delays = [index - detected_index for detected_index, index in zip(detected_indexes, true_change_indexes)]\n",
    "\n",
    "    if len(delays) > 0:\n",
    "        average_delay = sum(delays) / len(delays)\n",
    "        return average_delay\n",
    "    else:\n",
    "        return 0  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_false_detection_rate(true_change_indexes, detected_indexes):\n",
    "    total_drifts = len(true_change_indexes)\n",
    "    total_detected = len(detected_indexes)\n",
    "    false_detections = total_detected - total_drifts\n",
    "    fdr = false_detections / total_drifts\n",
    "    return fdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_miss_detection_rate(true_change_indexes, detected_indexes):\n",
    "    total_drifts = len(true_change_indexes)\n",
    "    total_detected = len(detected_indexes)\n",
    "    mdr = (total_drifts - total_detected) / total_drifts\n",
    "    return mdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rate_of_drift(detected_indexes, total_time):\n",
    "    total_detected = len(detected_indexes)\n",
    "    rod = total_detected / total_time\n",
    "    return rod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADWIN Algorithm Implementation\n",
    "class ADWIN:\n",
    "    def __init__(self, delta=0.002):\n",
    "        self.delta = delta\n",
    "        self.window = []\n",
    "        self.total = 0\n",
    "        self.variance = 0\n",
    "        self.width = 0\n",
    "\n",
    "    def add_element(self, value):\n",
    "        self.window.append(value)\n",
    "        self.width += 1\n",
    "        self.total += value\n",
    "        self.update_variance(value)\n",
    "\n",
    "        if self.width > 1:\n",
    "            cutpoint = self.find_cut()\n",
    "            if cutpoint:\n",
    "                self.window = self.window[cutpoint:]\n",
    "                self.width = len(self.window)\n",
    "                self.total = sum(self.window)\n",
    "                self.recalculate_variance()\n",
    "        return cutpoint\n",
    "\n",
    "    def update_variance(self, value):\n",
    "        mean = self.total / self.width\n",
    "        self.variance += (value - mean) * (value - self.total / (self.width - 1))\n",
    "\n",
    "    def find_cut(self):\n",
    "        for i in range(1, self.width):\n",
    "            w0 = i\n",
    "            w1 = self.width - i\n",
    "            mean0 = sum(self.window[:i]) / w0\n",
    "            mean1 = sum(self.window[i:]) / w1\n",
    "            var0 = sum((x - mean0) ** 2 for x in self.window[:i]) / w0\n",
    "            var1 = sum((x - mean1) ** 2 for x in self.window[i:]) / w1\n",
    "            m = 1 / w0 + 1 / w1\n",
    "            epsilon = ((2 / (m - 1)) * log(4 / self.delta)) ** 0.5\n",
    "            if abs(mean0 - mean1) > epsilon:\n",
    "                return i\n",
    "        return None\n",
    "\n",
    "    def recalculate_variance(self):\n",
    "        mean = self.total / self.width\n",
    "        self.variance = sum((x - mean) ** 2 for x in self.window)\n",
    "\n",
    "def log(x):\n",
    "    from math import log\n",
    "    return log(x)\n",
    "\n",
    "def abs(x):\n",
    "    return x if x >= 0 else -x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the model from the file\n",
    "model = joblib.load('../albert/model/random_forest_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_df(df):\n",
    "    label = df.pop('attack')\n",
    "    return df, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HaiConsumer:\n",
    "    def __init__(self, topic, bootstrap_servers):\n",
    "        self.topic = topic\n",
    "        self.bootstrap_servers = bootstrap_servers\n",
    "        self.consumer = KafkaConsumer(\n",
    "            self.topic,\n",
    "            bootstrap_servers=self.bootstrap_servers,\n",
    "            auto_offset_reset='earliest',\n",
    "            enable_auto_commit=True,\n",
    "            value_deserializer=lambda x: loads(x.decode('utf-8')))\n",
    "\n",
    "    def consume(self):\n",
    "        # Initialize ADWIN detector\n",
    "        adwin = ADWIN(delta=0.002)\n",
    "\n",
    "        counter = 0\n",
    "        # Perform change detection on the test set\n",
    "        global change_points\n",
    "        global accuracies\n",
    "        global whole_df\n",
    "        global whole_labels\n",
    "        change_points = []\n",
    "        accuracies = []\n",
    "        whole_df = pd.DataFrame()\n",
    "        whole_labels = pd.Series()\n",
    "        # write to file\n",
    "        with influxdb_client.InfluxDBClient(url=url, token=token, org=org) as client:\n",
    "            write_api = client.write_api(write_options=SYNCHRONOUS)\n",
    "            for i, message in enumerate(self.consumer):\n",
    "                message = message.value\n",
    "                # selected_columns = {key: value for key, value in message.items() if key in columns_to_scale_and_monitor}\n",
    "                df = pd.DataFrame([message])\n",
    "                x_i, y_i = split_df(df)\n",
    "                x_i = x_i.iloc[0:1]\n",
    "\n",
    "                whole_df = pd.concat([whole_df, x_i], ignore_index=True)\n",
    "                whole_labels = pd.concat([whole_labels, y_i], ignore_index=True)\n",
    "\n",
    "                # Predict using the RandomForest model\n",
    "                pred = model.predict(x_i)\n",
    "\n",
    "                # Check for a change point using ADWIN\n",
    "                if adwin.add_element(pred == int(y_i)):\n",
    "                    change_points.append(i)\n",
    "\n",
    "                # Calculate accuracy at each step\n",
    "                accuracy = model.score(whole_df.iloc[:i + 1], whole_labels.iloc[:i + 1])\n",
    "                accuracies.append(accuracy)\n",
    "\n",
    "                print(f'accuracy: {accuracy}   -    drift_detected: {int(y_i)}')\n",
    "\n",
    "                p = influxdb_client.Point(\"ChangeDetection_ADWIN\").field('accuracy', accuracy)\n",
    "                write_api.write(bucket, org, p)\n",
    "\n",
    "                p = influxdb_client.Point(\"ChangeDetection_ADWIN\").field('drift_detected', int(y_i))\n",
    "                write_api.write(bucket, org, p)\n",
    "                counter += 1\n",
    "                if counter > 5000:\n",
    "                    break\n",
    "\n",
    "            client.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\irenm\\AppData\\Local\\Temp\\ipykernel_21872\\2933331418.py:25: FutureWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  whole_labels = pd.Series()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'P1_B2004': {'0': 0.0983}, 'P1_B2016': {'0': 1.0702}, 'P1_B3004': {'0': 399.2321}, 'P1_B3005': {'0': 1110.3986}, 'P1_B4002': {'0': 32.0}, 'P1_B4005': {'0': 0.0}, 'P1_B400B': {'0': 28.9981}, 'P1_B4022': {'0': 35.7395}, 'P1_FCV01D': {'0': 0.0}, 'P1_FCV01Z': {'0': 0.2838}, 'P1_FCV02D': {'0': 100.0}, 'P1_FCV02Z': {'0': 95.5215}, 'P1_FCV03D': {'0': 53.785}, 'P1_FCV03Z': {'0': 55.0323}, 'P1_FT01': {'0': 132.9803}, 'P1_FT01Z': {'0': 711.2531}, 'P1_FT02': {'0': 5.188}, 'P1_FT02Z': {'0': 29.9914}, 'P1_FT03': {'0': 312.0803}, 'P1_FT03Z': {'0': 1112.1606}, 'P1_LCV01D': {'0': 19.6892}, 'P1_LCV01Z': {'0': 19.2886}, 'P1_LIT01': {'0': 396.6266}, 'P1_PCV01D': {'0': 35.21}, 'P1_PCV01Z': {'0': 36.3403}, 'P1_PCV02D': {'0': 12}, 'P1_PCV02Z': {'0': 12.0102}, 'P1_PIT01': {'0': 1.0843}, 'P1_PIT02': {'0': 0.2084}, 'P1_TIT01': {'0': 36.0779}, 'P1_TIT02': {'0': 37.3596}, 'P2_24Vdc': {'0': 28.0221}, 'P2_Auto': {'0': 1}, 'P2_Emgy': {'0': 0}, 'P2_On': {'0': 1}, 'P2_SD01': {'0': 20}, 'P2_SIT01': {'0': 815.0}, 'P2_TripEx': {'0': 0}, 'P2_VT01e': {'0': 11.8983}, 'P2_VXT02': {'0': -3.2879}, 'P2_VXT03': {'0': -1.2942}, 'P2_VYT02': {'0': 0.2115}, 'P2_VYT03': {'0': 1.8135}, 'P3_LCP01D': {'0': 1167.0}, 'P3_LCV01D': {'0': 12767.0}, 'P3_LH': {'0': 70}, 'P3_LL': {'0': 10}, 'P3_LT01': {'0': 28.9352}, 'P4_HT_FD': {'0': 0.0005}, 'P4_HT_LD': {'0': 64.4604}, 'P4_HT_PO': {'0': 57.8704}, 'P4_HT_PS': {'0': 0}, 'P4_LD': {'0': 395.0195}, 'P4_ST_FD': {'0': -0.0004}, 'P4_ST_LD': {'0': 330.6568}, 'P4_ST_PO': {'0': 328.9388}, 'P4_ST_PS': {'0': 50.9871}, 'P4_ST_PT01': {'0': 9973.0}, 'P4_ST_TT01': {'0': 27629.0}, 'attack': {'0': 0}}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21872\\687531162.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtopic\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'hai-preprocessed-mao'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mbootstrap_servers\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'localhost:9092'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mconsumer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHaiConsumer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtopic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbootstrap_servers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mconsumer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconsume\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_21872\\2933331418.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m                 \u001b[0mcounter\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mcounter\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m5000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m             \u001b[0mclient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\irenm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    819\u001b[0m         \u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    820\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mndarray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m         \"\"\"\n\u001b[1;32m--> 823\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    826\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproba\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\irenm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[0mclasses\u001b[0m \u001b[0mcorresponds\u001b[0m \u001b[0mto\u001b[0m \u001b[0mthat\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mattribute\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mterm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    862\u001b[0m         \"\"\"\n\u001b[0;32m    863\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 865\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    866\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    867\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m         \u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_partition_estimators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\irenm\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m         \"\"\"\n\u001b[0;32m    597\u001b[0m         Validate X whenever one tries to predict, apply, predict_proba.\"\"\"\n\u001b[0;32m    598\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintc\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No support for np.int64 index based sparse matrices\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\irenm\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    600\u001b[0m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    602\u001b[0m                 \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 604\u001b[1;33m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"X\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    605\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    606\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\irenm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    915\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    916\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    918\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 919\u001b[1;33m                 raise ValueError(\n\u001b[0m\u001b[0;32m    920\u001b[0m                     \u001b[1;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    921\u001b[0m                 ) from complex_warning\n\u001b[0;32m    922\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\irenm\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    376\u001b[0m         \u001b[1;31m# Use NumPy API to support order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    378\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 380\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    381\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[1;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         \u001b[1;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\irenm\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m   2063\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2064\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'dict'"
     ]
    }
   ],
   "source": [
    "topic = 'hai-preprocessed-mao'\n",
    "bootstrap_servers = ['localhost:9092']\n",
    "consumer = HaiConsumer(topic, bootstrap_servers)\n",
    "consumer.consume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class HaiConsumer:\n",
    "    def __init__(self, topic, bootstrap_servers):\n",
    "        self.topic = topic\n",
    "        self.bootstrap_servers = bootstrap_servers\n",
    "        self.consumer = KafkaConsumer(\n",
    "            self.topic,\n",
    "            bootstrap_servers=self.bootstrap_servers,\n",
    "            auto_offset_reset='earliest',\n",
    "            enable_auto_commit=True,\n",
    "            value_deserializer=lambda x: loads(x.decode('utf-8')))\n",
    "\n",
    "    def consume(self):\n",
    "        # Create an instance of the ADWIN class\n",
    "        ADWIN_detector = ADWIN()\n",
    "\n",
    "        # Assuming url, token, org, and bucket are defined\n",
    "        with influxdb_client.InfluxDBClient(url=url, token=token, org=org) as client:\n",
    "            write_api = client.write_api(write_options=SYNCHRONOUS)\n",
    "\n",
    "            for i, message in enumerate(self.consumer):\n",
    "                message = message.value\n",
    "                df = pd.DataFrame([message])\n",
    "                df = df.iloc[:, 1:]\n",
    "\n",
    "                # Assuming model.predict() returns a single value for detection\n",
    "                random_forest_detection = model.predict(df)\n",
    "                \n",
    "                # List to store detected change points using ADWIN\n",
    "                detected_indexes_ADWIN = []\n",
    "                stream_size = df.shape[0]\n",
    "\n",
    "                # Initialize ADWIN for change detection\n",
    "                adwin = ADWIN(delta=0.002)\n",
    "\n",
    "                # List detected change points\n",
    "                detected_indexes_adwin = []\n",
    "\n",
    "                error = int(random_forest_detection != test_labels.iloc[i])\n",
    "\n",
    "                # Update ADWIN with the error signal\n",
    "                adwin.add_element(error)\n",
    "\n",
    "                # Check for change detection\n",
    "                if adwin.check_drift():\n",
    "                    detected_indexes_adwin.append(i)\n",
    "\n",
    "\n",
    "\n",
    "                # Update ADWIN with the label (1 for anomaly, 0 for normal)\n",
    "                ADWIN_detector.add_element(random_forest_detection)\n",
    "                if ADWIN_detector.detected_change():\n",
    "                    detected_indexes_ADWIN.append(i)\n",
    "\n",
    "                print(\"Detected Change Points (ADWIN):\", detected_indexes_ADWIN)\n",
    "\n",
    "                # Evaluate change detection performance using ADWIN\n",
    "                average_delay_ADWIN = calculate_delay_of_detection(random_forest_detection, detected_indexes_ADWIN)\n",
    "                fdr_ADWIN = calculate_false_detection_rate(random_forest_detection, detected_indexes_ADWIN)\n",
    "                mdr_ADWIN = calculate_miss_detection_rate(random_forest_detection, detected_indexes_ADWIN)\n",
    "                rod_ADWIN = calculate_rate_of_drift(detected_indexes_ADWIN, total_time=stream_size - 500)\n",
    "\n",
    "                p = influxdb_client.Point(\"Change_Detection_ADWIN\").field('fdr_ADWIN', fdr_ADWIN)\n",
    "                write_api.write(bucket, org, p)\n",
    "\n",
    "                p = influxdb_client.Point(\"Change_Detection_ADWIN\").field('mdr_ADWIN', mdr_ADWIN)\n",
    "                write_api.write(bucket, org, p)\n",
    "\n",
    "                p = influxdb_client.Point(\"Change_Detection_ADWIN\").field('rod_ADWIN', rod_ADWIN)\n",
    "                write_api.write(bucket, org, p)\n",
    "\n",
    "                sleep(3)\n",
    "                if i > 100:\n",
    "                    break\n",
    "\n",
    "            client.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ADWIN' object has no attribute 'detected_change'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m bootstrap_servers \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocalhost:9092\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      3\u001b[0m consumer \u001b[38;5;241m=\u001b[39m HaiConsumer(topic, bootstrap_servers)\n\u001b[1;32m----> 4\u001b[0m \u001b[43mconsumer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconsume\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[32], line 33\u001b[0m, in \u001b[0;36mHaiConsumer.consume\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Update ADWIN with the label (1 for anomaly, 0 for normal)\u001b[39;00m\n\u001b[0;32m     32\u001b[0m ADWIN_detector\u001b[38;5;241m.\u001b[39madd_element(random_forest_detection)\n\u001b[1;32m---> 33\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mADWIN_detector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetected_change\u001b[49m():\n\u001b[0;32m     34\u001b[0m     detected_indexes_ADWIN\u001b[38;5;241m.\u001b[39mappend(i)\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDetected Change Points (ADWIN):\u001b[39m\u001b[38;5;124m\"\u001b[39m, detected_indexes_ADWIN)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ADWIN' object has no attribute 'detected_change'"
     ]
    }
   ],
   "source": [
    "\n",
    "topic = 'hai-input'\n",
    "bootstrap_servers = ['localhost:9092']\n",
    "consumer = HaiConsumer(topic, bootstrap_servers)\n",
    "consumer.consume()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
